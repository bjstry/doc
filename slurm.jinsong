启动
systemctl start munge
systemctl start slurmctld //主节点
systemctl start slurmdbd  //可选
systemctl start slurmd    //子节点

sbatch -n 20 -w "node[01-02]" -o my.out my.script //提交一个任务用20核，并且指定node01,node02节点
srun -N3 -l /bin/hostname  //请求3个节点执行
srun -n3 -l /bin/hostnae   //请求3个核执行
srun  -n8 -N2    -w "node[1-2]" -p big  --ntasks-per-node=4  --mem-per-cpu=100M /bin/hostname //两个节点(node1-2)共8个核心执行，每个节点四个核100M内存
srun  -N2 -n8  /bin/hostname  //两个节点共8个核心执行，自动分配核心

job.bt //脚本

#!/bin/sh
#SBATCH 
-N  //使用的节点数
-n  //作业要加载的任务数(简单理解核数,自由分配)
-p debug  //指定分区,类似队列
* -c  //每个任务需要的处理器数
-o out.file //指定输出文件
-t 100 //指定计算时间，超时退出
--mem //指定每个节点使用的内存数，单位为MB
--job-name=testname //作业名称
--ntasks-per-node=4 //指定每个节点使用的任务数(每个节点核数)        
cd $SLURM_SUBMIT_DIR
srun  -n4 --mpi=pmi2 --mem=1000 /opt/software/lammps-16Mar18/src/lmp_intel_mpich  < in.comb3  2>&1 | tee test.log

slurm.conf 
NodeName=node05 Procs=48 RealMemory=120000 MaxTime=INFINITE State=IDLE

 select/cons_res  //精细化配置可用资源

    CPU (CR_CPU): CPU as a consumable resource.
        No notion of sockets, cores, or threads.
        On a multi-core system CPUs will be cores.
        On a multi-core/hyperthread system CPUs will be threads.
        On a single-core systems CPUs are CPUs. ;-)
    Board (CR_Board): Baseboard as a consumable resource.
    Socket (CR_Socket): Socket as a consumable resource.
    Core (CR_Core): Core as a consumable resource.
    Memory (CR_Memory) Memory only as a consumable resource. Note! CR_Memory assumes OverSubscribe=Yes
    Socket and Memory (CR_Socket_Memory): Socket and Memory as consumable resources.
    Core and Memory (CR_Core_Memory): Core and Memory as consumable resources.
    CPU and Memory (CR_CPU_Memory) CPU and Memory as consumable resources.

sacct      用于报告运行中或者已完成作业的作业或作业步骤的记帐信息
salloc     用于为作业实时分配资源，这通常用于分配资源和生成shell，然后使用shell执行srun命令来启动并行任务。
sattach   用于将标准输入、输出和错误加信号功能附加到当前正在运行的作业或作业步骤。可以多次附加到作业或从作业中分离。
sbatch    用于提交脚本以供以后执行。脚本通常包含一个或多个srun命令来启动并行任务。
sbcast     用于将文件从本地磁盘传输到分配给作业的节点上的本地磁盘，这可以用于有效地使用无盘计算节点，或提供相对于共享文件系统的改进性能。
scancel   用于取消挂起或正在运行的作业或作业步骤。它还可以用于向与正在运行的作业或作业步骤相关联的所有进程发送任意信号。
scontrol  是用于查看和/或修改Slurm状态的管理工具。请注意，许多scontrol命令只能用root用户执行。
sinfo       报告由Slurm管理的分区和节点的状态。它有各种各样的过滤、排序和格式化选项。
sprio       用于显示影响作业优先级的组件的详细视图。
squeue    报告作业或作业步骤的状态。它有各种各样的过滤、排序和格式化选项。默认情况下，它按优先级顺序报告正在运行的作业，然后按优先级顺序报告挂起的作业。
srun        用于提交作业以供执行或实时启动作业步骤。srun有多种选择来指定资源需求，包括：最小和最大节点数、核心数、要使用或不使用的指定节点，以及特定的节点特性（多少内存、磁盘空间、某些必需的特性等）。一个作业可以包含多个作业步骤，在作业的节点分配内，对独立或共享的资源按顺序或并行执行。
sshare     显示有关群集上fairshare(公平份额?)使用情况的详细信息。请注意，这只在使用priority/multifactor插件时才可行。
sstat       用于获取有关正在运行的作业或作业步骤使用的资源的信息。
strigger  用于设置、获取或查看事件触发器事件。触发器包括节点关闭或作业接近其时间限制等情况。
sview      是一个图形用户界面，用于获取和更新Slurm管理的作业、分区和节点的状态信息。
